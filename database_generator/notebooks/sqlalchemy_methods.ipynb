{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing SQLAlchemy methods\n",
    "\n",
    "### Methods to Build:\n",
    "\n",
    "- Setup: Connecting to the Database\n",
    "- Create a Table for Pump Data\n",
    "- Insert Data into the Table\n",
    "- Query Data from the Table\n",
    "- Update Data in the Table\n",
    "- Delete Data from the Table\n",
    "- Use SQLAlchemy ORM to Define Models and Perform CRUD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from database_generator.logging_configuration import setup_logging_for_this_script\n",
    "setup_logging_for_this_script()\n",
    "# Get the logger for this module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "from database_generator.helpers import (\n",
    "    get_config_path,\n",
    "    load_and_process_params,\n",
    ")\n",
    "\n",
    "from database_generator.get_data import (\n",
    "    generate_stable_toy_data,\n",
    "    introduce_exponential_anomalies,\n",
    "    simulate_broken_sensor,\n",
    ")\n",
    "\n",
    "from database_generator.evaluate import (\n",
    "    overlaid_plots_with_plotly,\n",
    ")\n",
    "\n",
    "from database_generator.db_operations import(\n",
    "    create_sql_alchemy_engine,\n",
    "    get_last_timestamp,\n",
    "    query_data_by_datetime,\n",
    "    store_pandas_dataframe_into_postegre,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to the .json file from the environment\n",
    "\n",
    "path_for_the_json_file = get_config_path()\n",
    "path_for_the_json_file\n",
    "\n",
    "config_dict = load_and_process_params(path_for_the_json_file)\n",
    "\n",
    "start_date_for_the_toy_dataset = config_dict['start_date_for_the_toy_dataset']\n",
    "number_of_rows_for_stable_toy_data = config_dict['number_of_rows_for_stable_toy_data']\n",
    "seed_for_the_stable_dataset = config_dict['seed_for_the_stable_dataset']\n",
    "\n",
    "# Example usage\n",
    "df_stable = generate_stable_toy_data(number_of_rows=number_of_rows_for_stable_toy_data, start_date=start_date_for_the_toy_dataset, seed_for_random=42)\n",
    "\n",
    "# Create an engine using environment variables or specified parameters\n",
    "engine = create_sql_alchemy_engine(\n",
    "    # user='my_user',\n",
    "    # password='my_secrets',\n",
    "    # host='localhost',\n",
    "    # port=5432,\n",
    "    # dbname='data_generator_v1'\n",
    ")\n",
    "\n",
    "# Store pandas df into postgre\n",
    "\n",
    "store_pandas_dataframe_into_postegre(df=df_stable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stable.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stable.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# theoretical stuff\n",
    "\n",
    "### The Engine in SQLAlchemy is a core object that represents the interface to the database. Here’s a breakdown of what the Engine does:\n",
    "\n",
    "- Connection Pooling: The Engine manages a pool of database connections. When you execute a query, the Engine provides a connection from this pool, making it efficient to execute multiple queries without needing to establish a new connection each time.\n",
    "\n",
    "- Database Dialect: The Engine is configured with a dialect that is specific to the type of database you're using (PostgreSQL in this case). This dialect translates SQLAlchemy commands into the appropriate SQL for your database system.\n",
    "\n",
    "- Execution Context: The Engine provides the execution context for SQL queries. It takes SQL expressions and translates them into the SQL string that is sent to the database.\n",
    "\n",
    "- Thread-Safe: The Engine is designed to be shared among multiple threads, and it's safe to use concurrently. This is especially useful for web applications where multiple requests need to interact with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Syntax\n",
    "\n",
    "### 1. with engine.connect() as connection:\n",
    "Purpose: This line is using a context manager (with statement) to create a new database connection from the SQLAlchemy engine.\n",
    "\n",
    "engine.connect():\n",
    "\n",
    "This method is used to create a new Connection object. The Connection object represents an active database connection. It provides a way to execute SQL statements, manage transactions, and interact with the database.\n",
    "When you call engine.connect(), SQLAlchemy establishes a connection to the database from the connection pool maintained by the engine.\n",
    "with Statement (Context Manager):\n",
    "\n",
    "The with statement ensures that resources are properly managed. When the code block inside the with statement is done executing, it automatically releases the connection back to the pool (or closes it if it's no longer needed). This prevents resource leaks and ensures efficient use of connections.\n",
    "It also handles any exceptions that might occur within the block, ensuring the connection is properly closed even if an error occurs.\n",
    "Benefit of Using with:\n",
    "\n",
    "Automatic cleanup: You don’t need to manually close the connection. It’s done automatically when the block is exited, either after successful execution or an error.\n",
    "Reduces boilerplate code: You don’t need to write explicit try/finally blocks to ensure cleanup.\n",
    "\n",
    "### 2. connection.execute()\n",
    "Purpose: This method is used to execute a SQL statement on the database.\n",
    "\n",
    "How It Works:\n",
    "\n",
    "connection.execute(...) takes an Executable object (like text()), a SQL expression, or a SQLAlchemy statement object (e.g., select(), insert(), update(), delete()), and sends it to the database for execution.\n",
    "Why Use .execute()?:\n",
    "\n",
    "It abstracts the complexity of sending SQL commands to the database, making it easier to work with different database backends (e.g., PostgreSQL, MySQL, SQLite) without needing to change your code.\n",
    ".execute() is a powerful function that supports a wide range of SQLAlchemy constructs, making it versatile for both raw SQL execution and ORM-based queries.\n",
    "\n",
    "### 3. .fetchone()\n",
    "Purpose: This method fetches a single row from the result set of the executed SQL query.\n",
    "\n",
    "How It Works:\n",
    "\n",
    "When you execute a SQL query that returns data (like SELECT), the execute() method returns a Result object.\n",
    "Calling .fetchone() on the Result object retrieves the next row of the result set as a tuple.\n",
    "If there are no more rows available, .fetchone() returns None.\n",
    "Why Use .fetchone()?:\n",
    "\n",
    "Efficient Memory Usage: If you only need one row from the result set, .fetchone() is more memory-efficient than .fetchall(), which retrieves all rows at once.\n",
    "Useful for Single Row Queries: If you know your query is designed to return only one row (e.g., SELECT 1), .fetchone() is appropriate.\n",
    "\n",
    "### Summary\n",
    "- engine.connect(): Establishes a connection to the database.\n",
    "- with ... as ...:: A context manager to handle resource cleanup automatically.\n",
    "- connection.execute(...): Executes a SQL statement or SQLAlchemy expression.\n",
    "- fetchone(): Retrieves the next row from the result set of the executed SQL statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. metadata = MetaData()\n",
    "\n",
    "- MetaData in SQLAlchemy:\n",
    "\n",
    "MetaData is a container object in SQLAlchemy that holds information about the database schema (i.e., tables, columns, constraints).\n",
    "It acts as a central registry that stores all the schema constructs, such as tables, columns, and other schema elements.\n",
    "When you create a MetaData object, you're essentially creating a blank registry that will hold the structure of your tables.\n",
    "Purpose in the Function:\n",
    "\n",
    "In the context of the create_table_from_dataframe function, metadata = MetaData() is used to define a new, empty metadata object where we can register our table definitions. This object will then be used to generate SQL commands to create the tables in the actual database.\n",
    "\n",
    "### 2. table = Table(table_name, metadata, *columns)\n",
    "\n",
    "- What is Table in SQLAlchemy?\n",
    "\n",
    "Table is a SQLAlchemy class that represents a database table. It defines the table's name, the columns it contains, the data types for each column, and any other metadata such as primary keys and foreign keys.\n",
    "How Table is Defined in the Code:\n",
    "\n",
    "table = Table(table_name, metadata, *columns):\n",
    "table_name: The name of the table you want to create in the database.\n",
    "metadata: The MetaData instance where this table's schema will be registered.\n",
    "*columns: A list of Column objects that define the structure of the table (e.g., column names and their types).\n",
    "By defining the table this way, we are dynamically creating a schema based on the provided DataFrame.\n",
    "Where table is Used:\n",
    "\n",
    "The table object itself is not directly used later in the function. Instead, its definition is registered in the metadata object. When we call metadata.create_all(engine), it uses all the table definitions registered in metadata to create the tables in the database.\n",
    "\n",
    "Why It Seems Unused:\n",
    "Although it looks like table is not being used, it is indeed crucial for creating the schema. The table definition is stored in metadata when we define it with Table(table_name, metadata, *columns).\n",
    "\n",
    "### 3. metadata.create_all(engine)\n",
    "\n",
    "- How metadata.create_all(engine) Works:\n",
    "\n",
    "metadata.create_all(engine) is a method that generates SQL CREATE TABLE statements for all the table objects registered with the MetaData instance (metadata) and executes them against the provided database engine.\n",
    "The engine represents the connection to the database. When you call create_all(engine), SQLAlchemy translates the table definitions in metadata into the appropriate SQL commands for the specific database dialect (e.g., PostgreSQL, MySQL) and runs them to create the tables.\n",
    "What Happens Under the Hood:\n",
    "\n",
    "For each Table object registered in metadata, SQLAlchemy generates the SQL command for creating that table.\n",
    "If you have multiple tables defined within metadata, it will create all of them in the database.\n",
    "It also checks if the table already exists in the database. If it does, it will skip creating that table (unless specified otherwise).\n",
    "\n",
    "### Summary of the Process\n",
    "metadata = MetaData(): Creates a container to hold all the table definitions.\n",
    "table = Table(table_name, metadata, *columns): Defines a table schema dynamically and registers it with the metadata object.\n",
    "metadata.create_all(engine): Generates and executes the SQL commands to create all tables registered in metadata in the connected database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Inspector Usage\n",
    "The Inspector is a class in SQLAlchemy that provides a generalized interface to database schema information. It's a powerful tool for introspecting (i.e., examining) the schema of a database.\n",
    "\n",
    "- How the Inspector Works:\n",
    "\n",
    "1. What is Inspector:\n",
    "\n",
    "Inspector is part of SQLAlchemy's sqlalchemy.engine.reflection module.\n",
    "\n",
    "It provides methods to inspect database schema details such as tables, columns, indexes, constraints, etc.\n",
    "Creating an Inspector Instance:\n",
    "\n",
    "- inspector = inspect(engine):\n",
    "inspect() is a function that returns an instance of the Inspector class for a given Engine or Connection.\n",
    "\n",
    "The engine parameter is the SQLAlchemy Engine instance connected to the database.\n",
    "When you call inspect(engine), SQLAlchemy constructs an Inspector object that provides methods to interact with the database schema.\n",
    "Checking for Table Existence with Inspector:\n",
    "\n",
    "- inspector.has_table(table_name):\n",
    "This method checks if a table with the specified name (table_name) exists in the current database schema.\n",
    "If the table exists, it returns True; otherwise, it returns False.\n",
    "This is useful for ensuring that a table is not created if it already exists, preventing potential conflicts or errors.\n",
    "\n",
    "2. Other Common Inspector Methods:\n",
    "\n",
    "- get_table_names(): Returns a list of all table names in the current schema.\n",
    "- get_columns(table_name): Returns a list of column names and their details for a specified table.\n",
    "- get_primary_keys(table_name): Returns a list of primary key column names for a specified table.\n",
    "- get_foreign_keys(table_name): Returns a list of foreign keys and their details for a specified table.\n",
    "- get_indexes(table_name): Returns a list of indexes and their details for a specified table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "1. Convert DataFrame to List of Dictionaries:\n",
    "- df.to_dict(orient='records'): This converts the DataFrame into a list of dictionaries, where each dictionary represents a row of data. This is compatible with SQLAlchemy's bulk insert operations.\n",
    "Prepare the Insert Statement:\n",
    "\n",
    "\n",
    "2. insert(table): Creates an INSERT SQL statement for the specified table object.\n",
    "Execute Bulk Insert:\n",
    "\n",
    "\n",
    "3. connection.execute(insert_stmt, data_to_insert): Executes the INSERT statement using the connection object. This performs a bulk insert of all the rows in one operation.\n",
    "\n",
    "\n",
    "4. Commit the Transaction:\n",
    "- connection.commit(): Commits the transaction to save the changes to the database.\n",
    "\n",
    "### Executing the Insert Statement:\n",
    "\n",
    "- connection.execute(insert_stmt, data_to_insert) is the core of the operation. Here’s what happens under the hood:\n",
    "SQLAlchemy Engine Prepares the SQL Statement: The insert_stmt object, along with data_to_insert, is handed over to SQLAlchemy's engine and connection objects.\n",
    "\n",
    "- Generating Parameterized SQL: SQLAlchemy generates a parameterized SQL query. Parameterized queries are used to safely insert data, protecting against SQL injection and improving performance. For example:\n",
    "sql\n",
    "\n",
    "- Example:\n",
    "\n",
    "INSERT INTO sensor_data (index_and_id, Temperature_C, Pressure_MPa, ...)\n",
    "\n",
    "VALUES (:index_and_id_1, :Temperature_C_1, :Pressure_MPa_1, ...),\n",
    "       (:index_and_id_2, :Temperature_C_2, :Pressure_MPa_2, ...),\n",
    "       ...\n",
    "\n",
    "The placeholders (:index_and_id_1, :Temperature_C_1, etc.) represent the parameterized query placeholders that will be replaced by the actual values from data_to_insert.\n",
    "\n",
    "- Bulk Insertion:\n",
    "SQLAlchemy automatically bundles the multiple rows from data_to_insert and inserts them in a single bulk operation.\n",
    "This approach is more efficient than inserting rows one by one, as it reduces the number of database round-trips.\n",
    "The actual database adapter (in this case, psycopg2 for PostgreSQL) handles the underlying bulk insertion logic, and SQLAlchemy provides a convenient interface for interacting with it.\n",
    "Committing the Transaction:\n",
    "\n",
    "- After executing the execute() method, you call connection.commit() to commit the transaction. This makes all the changes (i.e., inserted rows) persistent in the database.\n",
    "If you were to omit commit(), the changes would not be saved to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "database_generator",
   "language": "python",
   "name": "database_generator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
