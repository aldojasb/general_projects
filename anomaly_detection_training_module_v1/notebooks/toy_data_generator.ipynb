{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "from typing import Optional, Literal, NewType\n",
    "import json\n",
    "\n",
    "\n",
    "# Get the logger for this module\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 20:28:34 - INFO - Logging is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "from anomaly_detection_training_module_v1 import timestamp_for_this_experiment # get global variable from __init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_path():\n",
    "    # Check if the environment variable is set\n",
    "    env_path = os.getenv('PATH_TO_THE_CONFIGURATION_FILE')\n",
    "    \n",
    "    if env_path:\n",
    "        return env_path\n",
    "    \n",
    "    # If not, parse the command-line arguments\n",
    "    parser = argparse.ArgumentParser(description='Provide the path to the configuration file.')\n",
    "    parser.add_argument('--config', type=str, help='Path to the configuration file')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.config:\n",
    "        return args.config\n",
    "    else:\n",
    "        logging.error(\"Configuration file path must be provided\"\n",
    "                         \"either as an environment variable 'PATH_TO_THE_CONFIGURATION_FILE'\"\n",
    "                         \"or as a command-line argument '--config'.\")\n",
    "        \n",
    "        raise ValueError(\"Configuration file path must be provided\"\n",
    "                         \"either as an environment variable 'PATH_TO_THE_CONFIGURATION_FILE'\"\n",
    "                         \"or as a command-line argument '--config'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to the .json file from the environment\n",
    "\n",
    "path_for_the_json_file = get_config_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aldo/Repositories/general_projects/anomaly_detection_training_module_v1/notebooks/parameters_for_toy_data_experiments.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_for_the_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_params(file_path: str) -> tuple:\n",
    "    # Load parameters from JSON file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        params = json.load(file)\n",
    "\n",
    "\n",
    "    # Access nested parameter maps under the 'parameters_to_create_toy_data' key\n",
    "    start_date_for_the_toy_dataset = datetime.fromisoformat(\n",
    "    params[\"parameters_to_create_toy_data\"][\"start_date_for_the_toy_dataset\"].replace(\"Z\", \"+00:00\"))\n",
    "    # Display parameter\n",
    "    logging.info(\"start_date_for_the_normal_dataset:\")\n",
    "    logging.info(start_date_for_the_toy_dataset)\n",
    "\n",
    "    # Access nested parameter maps under the 'parameters_to_create_toy_data' key\n",
    "    seed_for_the_stable_dataset = params [\"parameters_to_create_toy_data\"][\"seed_for_the_stable_dataset\"]\n",
    "    # Display window sizes\n",
    "    logging.info(\"seed_for_the_stable_dataset:\")\n",
    "    logging.info(seed_for_the_stable_dataset)\n",
    "\n",
    "    # Access nested parameter maps under the 'parameters_to_create_toy_data' key\n",
    "    number_of_rows_for_stable_toy_data = params [\"parameters_to_create_toy_data\"][\"number_of_rows_for_stable_toy_data\"]\n",
    "    # Display window sizes\n",
    "    logging.info(\"number_of_rows_for_stable_toy_data:\")\n",
    "    logging.info(number_of_rows_for_stable_toy_data)\n",
    "\n",
    "    return (\n",
    "        start_date_for_the_toy_dataset,\n",
    "        number_of_rows_for_stable_toy_data,\n",
    "        seed_for_the_stable_dataset\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 20:28:37 - INFO - start_date_for_the_normal_dataset:\n",
      "2024-08-10 20:28:37 - INFO - 2024-08-10 15:00:00\n",
      "2024-08-10 20:28:37 - INFO - seed_for_the_stable_dataset:\n",
      "2024-08-10 20:28:37 - INFO - 300\n",
      "2024-08-10 20:28:37 - INFO - number_of_rows_for_stable_toy_data:\n",
      "2024-08-10 20:28:37 - INFO - 10000\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    start_date_for_the_toy_dataset,\n",
    "    numbnumber_of_rows_for_stable_toy_data,\n",
    "    seed_for_the_stable_dataset\n",
    "    ) = load_and_process_params(path_for_the_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_stable_toy_data(number_of_rows: int, start_date: str, seed_for_random: int = None) -> pd.DataFrame:\n",
    "    # Set the seed for reproducibility\n",
    "    if seed_for_random is not None:\n",
    "        np.random.seed(seed_for_random)\n",
    "    \n",
    "    # Generate a date range\n",
    "    date_range = pd.date_range(start=start_date, periods=number_of_rows, freq='H')\n",
    "    \n",
    "    # Generate base data with correlations\n",
    "    # Temperature: Normally distributed around 75Â°C with small fluctuations\n",
    "    temperature = np.random.normal(loc=75, scale=1, size=number_of_rows)\n",
    "    \n",
    "    # Pressure: Correlated with temperature, slightly decreasing with higher temperatures\n",
    "    pressure = 3 - 0.01 * (temperature - 75) + np.random.normal(loc=0, scale=0.05, size=number_of_rows)\n",
    "    \n",
    "    # Vibration: Low vibration under normal conditions, with slight random noise\n",
    "    vibration = np.random.normal(loc=0.3, scale=0.05, size=number_of_rows)\n",
    "    \n",
    "    # Flow Rate: Generally stable, slightly increasing with lower pressure (inverse correlation)\n",
    "    flow_rate = 300 + 10 * (3 - pressure) + np.random.normal(loc=0, scale=5, size=number_of_rows)\n",
    "    \n",
    "    # Humidity: Independent of the other variables, normal fluctuations\n",
    "    humidity = np.random.normal(loc=40, scale=5, size=number_of_rows)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Timestamp': date_range,\n",
    "        'Temperature_C': temperature,\n",
    "        'Pressure_MPa': pressure,\n",
    "        'Vibration_mm_s': vibration,\n",
    "        'Flow_Rate_l_min': flow_rate,\n",
    "        'Humidity_%': humidity\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df_stable = generate_stable_toy_data(number_of_rows=1000, start_date='2024-01-01', seed_for_random=42)\n",
    "print(df_stable.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection_training_module_v1",
   "language": "python",
   "name": "anomaly_detection_training_module_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
