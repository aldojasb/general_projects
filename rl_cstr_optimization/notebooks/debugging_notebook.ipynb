{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from rl.cstr.optimization.base_agent import compute_gae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trajectory_data():\n",
    "    \"\"\"\n",
    "    Fixture providing sample trajectory data for testing compute_gae.\n",
    "    \n",
    "    Creates realistic trajectory data that would be returned by collect_trajectories:\n",
    "    - rewards: Conversion efficiency rewards from CSTR control\n",
    "    - dones: Episode termination flags\n",
    "    - values: Critic's value estimates for each state\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (rewards, dones, values) for GAE computation\n",
    "    \"\"\"\n",
    "    # Sample trajectory data (10 timesteps)\n",
    "    rewards = [15.2, 12.8, 18.1, 14.5, 16.3, 13.7, 17.9, 15.8, 14.2, 16.7]\n",
    "    dones = [False, False, False, False, False, False, False, False, False, True]\n",
    "    values = [15.0, 13.0, 17.5, 14.0, 16.0, 13.5, 17.0, 15.5, 14.0, 16.5]\n",
    "    \n",
    "    return rewards, dones, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given: Sample trajectory data (10 timesteps)\n",
    "rewards, dones, values = sample_trajectory_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.2, 12.8, 18.1, 14.5, 16.3, 13.7, 17.9, 15.8, 14.2, 16.7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False, False, False, True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0, 13.0, 17.5, 14.0, 16.0, 13.5, 17.0, 15.5, 14.0, 16.5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When: Computing GAE with default parameters\n",
    "gae_lambda = 0.95\n",
    "gae_advantages_normalized, total_expected_future_rewards, raw_gae_advantages = compute_gae(rewards, dones, values, gae_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3105,  1.1703,  0.8678,  0.6285,  0.2950,  0.0233, -0.4003, -0.8421,\n",
       "        -1.2547, -1.7983])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae_advantages_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([105.8748,  99.7865,  95.4629,  84.9838,  77.2563,  66.8311,  57.9763,\n",
       "         43.5901,  30.0555,  16.7000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_expected_future_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90.8748, 86.7865, 77.9629, 70.9838, 61.2563, 53.3311, 40.9763, 28.0901,\n",
       "        16.0555,  0.2000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_gae_advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_normalized_manual = (raw_gae_advantages - raw_gae_advantages.mean()) / (raw_gae_advantages.std() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2432,  1.1102,  0.8233,  0.5963,  0.2799,  0.0221, -0.3797, -0.7989,\n",
       "        -1.1903, -1.7060])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_normalized_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3105,  1.1703,  0.8678,  0.6285,  0.2950,  0.0233, -0.4003, -0.8421,\n",
       "        -1.2547, -1.7983])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae_advantages_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_mean_1 = gae_advantages_normalized.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9605e-09)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_mean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_mean = gae_advantages_normalized.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9604645663569045e-09"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert advantages_mean < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_std_1 = gae_advantages_normalized.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0541)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_std_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_std = gae_advantages_normalized.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.054092526435852"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05409252643585205"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_std - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(advantages_std - \u001b[32m1.0\u001b[39m) < \u001b[32m1e-6\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "assert abs(advantages_std - 1.0) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages_std_2 = advantages_normalized_manual.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_std_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # def test_compute_gae_episode_termination(self, sample_trajectory_data):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae handles episode termination correctly.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Sample trajectory data with episode termination\n",
    "    #     rewards, dones, values = sample_trajectory_data\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle episode termination correctly\n",
    "    #     # Check that the last timestep has a done flag\n",
    "    #     assert dones[-1] == True, \\\n",
    "    #         \"Last timestep should have done=True\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are computed correctly\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_different_gamma(self, sample_trajectory_data):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with different gamma values.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Sample trajectory data\n",
    "    #     rewards, dones, values = sample_trajectory_data\n",
    "        \n",
    "    #     # When: Computing GAE with different gamma values\n",
    "    #     gamma_0_9 = 0.9\n",
    "    #     gamma_0_99 = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "        \n",
    "    #     gae_values_0_9, gae_advantages_0_9 = compute_gae(rewards, dones, values, gamma_0_9, gae_lambda)\n",
    "    #     gae_values_0_99, gae_advantages_0_99 = compute_gae(rewards, dones, values, gamma_0_99, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should work with different gamma values\n",
    "    #     # Check that both computations produce valid results\n",
    "    #     assert torch.all(torch.isfinite(gae_values_0_9)), \\\n",
    "    #         \"gae_values with gamma=0.9 should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages_0_9)), \\\n",
    "    #         \"gae_advantages with gamma=0.9 should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_values_0_99)), \\\n",
    "    #         \"gae_values with gamma=0.99 should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages_0_99)), \\\n",
    "    #         \"gae_advantages with gamma=0.99 should be finite\"\n",
    "        \n",
    "    #     # Check that results are different for different gamma values\n",
    "    #     assert not torch.allclose(gae_values_0_9, gae_values_0_99), \\\n",
    "    #         \"Different gamma values should produce different results\"\n",
    "\n",
    "    # def test_compute_gae_constant_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with constant rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with constant rewards\n",
    "    #     rewards = [10.0, 10.0, 10.0, 10.0, 10.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [10.0, 10.0, 10.0, 10.0, 10.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle constant rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_increasing_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with increasing rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with increasing rewards\n",
    "    #     rewards = [5.0, 10.0, 15.0, 20.0, 25.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [5.0, 10.0, 15.0, 20.0, 25.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle increasing rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_decreasing_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with decreasing rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with decreasing rewards\n",
    "    #     rewards = [25.0, 20.0, 15.0, 10.0, 5.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [25.0, 20.0, 15.0, 10.0, 5.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle decreasing rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_negative_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with negative rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with negative rewards\n",
    "    #     rewards = [-5.0, -10.0, -15.0, -20.0, -25.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [-5.0, -10.0, -15.0, -20.0, -25.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle negative rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_mixed_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with mixed positive and negative rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with mixed rewards\n",
    "    #     rewards = [5.0, -10.0, 15.0, -20.0, 25.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [5.0, -10.0, 15.0, -20.0, 25.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle mixed rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "\n",
    "    # def test_compute_gae_zero_rewards(self):\n",
    "    #     \"\"\"\n",
    "    #     Test that compute_gae works with zero rewards.\n",
    "    #     \"\"\"\n",
    "    #     # Given: Trajectory with zero rewards\n",
    "    #     rewards = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    #     dones = [False, False, False, False, True]\n",
    "    #     values = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        \n",
    "    #     # When: Computing GAE with default parameters\n",
    "    #     gamma = 0.99\n",
    "    #     gae_lambda = 0.95\n",
    "    #     gae_values, gae_advantages = compute_gae(rewards, dones, values, gamma, gae_lambda)\n",
    "        \n",
    "    #     # Then: GAE should handle zero rewards correctly\n",
    "    #     # Check that gae_values and gae_advantages have correct length\n",
    "    #     assert len(gae_values) == len(rewards), \\\n",
    "    #         \"gae_values length should match rewards length\"\n",
    "    #     assert len(gae_advantages) == len(rewards), \\\n",
    "    #         \"gae_advantages length should match rewards length\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are finite\n",
    "    #     assert torch.all(torch.isfinite(gae_values)), \\\n",
    "    #         \"gae_values should be finite\"\n",
    "    #     assert torch.all(torch.isfinite(gae_advantages)), \\\n",
    "    #         \"gae_advantages should be finite\"\n",
    "        \n",
    "    #     # Check that gae_values and gae_advantages are all zeros\n",
    "    #     assert torch.all(gae_values == 0), \\\n",
    "    #         \"gae_values should be all zeros for zero rewards\"\n",
    "    #     assert torch.all(gae_advantages == 0), \\\n",
    "    #         \"gae_advantages should be all zeros for zero rewards\"\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
